<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[JDBC]]></title>
    <url>%2F2019%2F03%2F23%2Fjdbc%2F</url>
    <content type="text"><![CDATA[JDBC入门概念JDBC是SUN公司定义的一套操作所有关系型数据库的java接口，各个数据库厂商去实现接口，提供数据库驱动jar包。JDBC编程真正执行的代码是驱动jar包中的实现类。 快速入门 导入驱动jar包 注册驱动 获取数据库连接对象Connection 定义sql 获取执行sql语句的对象 Statement 执行sql，接受返回结果 处理结果 释放资源 驱动jar包下载地址：https://dev.mysql.com/downloads/connector/j/5.1.html JDBC对象详解DriverManager（驱动管理对象）功能： 注册驱动 com.mysql.jdbc.Driver类中存在静态代码块 获取数据库连接 static Connection getConnection(String url, String user, String password) Connection（数据库连接对象）功能： 获取执行sql语句的对象 Statement createStatement() PreparedStatement prepareStatement(String sql) 管理事务 开启事务：void setAutoCommit(boolean autoCommit)，设置参数为false则开启事务 提交事务：commit() 回滚事务：rollback() Statement（执行sql对象）功能： 执行sql语句 boolean execute(String sql)：执行任意sql语句 int executeUpdate(String sql)：执行DML，DDL ResultSet executeQuery(String sql)：执行DQL ResultSet（结果集对象）ResultSet 对象具有指向其当前数据行的光标。最初，光标被置于第一行之前。next 方法将光标移动到下一行；因为该方法在 ResultSet 对象没有下一行时返回 false，所以可以在 while 循环中使用它来迭代结果集。 next()：光标向下一行 getX(参数)： X：数据类型，int getInt() 参数： int：代表列的编号，从1开始 String：列的字段名称 PreparedStatement（执行sql对象）功能： 解决sql注入问题，使用？作为占位符预编译sql语句。 效率更高 1234PreparedStatement pstmt = con.prepareStatement("UPDATE EMPLOYEES SET SALARY = ? WHERE ID = ?"); pstmt.setBigDecimal(1, 153833.00) pstmt.setInt(2, 110592) JDBC控制事务1. 数据库连接池###概念 实现 标准接口： 别人已实现的连接池： C3P0 Druid（阿里巴巴提供） C3P0官方地址：https://www.mchange.com/projects/c3p0/ 使用步骤 导入jar包 c3p0-oracle-thin-extras-0.9.5.2.jar mchange-commons-java-0.2.11.jar 数据库驱动包 定义配置文件文件名c3p0-config.xml，放在src目录下 创建数据库连接池对象DataSource ds = new ComboPooledDataSource(); 获取连接Connection conn = ds.getConnection(); democ3p0-config.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;c3p0-config&gt; &lt;default-config&gt; &lt;property name="driverClass"&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name="jdbcUrl"&gt;jdbc:mysql://localhost:3306/数据库&lt;/property&gt; &lt;property name="user"&gt;用户名&lt;/property&gt; &lt;property name="password"&gt;密码 &lt;/property&gt; &lt;property name="automaticTestTable"&gt;con_test&lt;/property&gt; &lt;property name="checkoutTimeout"&gt;30000&lt;/property&gt; &lt;property name="idleConnectionTestPeriod"&gt;30&lt;/property&gt; &lt;property name="initialPoolSize"&gt;10&lt;/property&gt; &lt;property name="maxIdleTime"&gt;30&lt;/property&gt; &lt;property name="maxPoolSize"&gt;100&lt;/property&gt; &lt;property name="minPoolSize"&gt;10&lt;/property&gt; &lt;property name="maxStatements"&gt;200&lt;/property&gt; &lt;user-overrides user="test-user"&gt; &lt;property name="maxPoolSize"&gt;10&lt;/property&gt; &lt;property name="minPoolSize"&gt;1&lt;/property&gt; &lt;property name="maxStatements"&gt;0&lt;/property&gt; &lt;/user-overrides&gt; &lt;/default-config&gt; &lt;!-- This app is massive! --&gt; &lt;named-config name="intergalactoApp"&gt; &lt;property name="acquireIncrement"&gt;50&lt;/property&gt; &lt;property name="initialPoolSize"&gt;100&lt;/property&gt; &lt;property name="minPoolSize"&gt;50&lt;/property&gt; &lt;property name="maxPoolSize"&gt;1000&lt;/property&gt; &lt;!-- intergalactoApp adopts a different approach to configuring statement caching --&gt; &lt;property name="maxStatements"&gt;0&lt;/property&gt; &lt;property name="maxStatementsPerConnection"&gt;5&lt;/property&gt; &lt;!-- he's important, but there's only one of him --&gt; &lt;user-overrides user="master-of-the-universe"&gt; &lt;property name="acquireIncrement"&gt;1&lt;/property&gt; &lt;property name="initialPoolSize"&gt;1&lt;/property&gt; &lt;property name="minPoolSize"&gt;1&lt;/property&gt; &lt;property name="maxPoolSize"&gt;5&lt;/property&gt; &lt;property name="maxStatementsPerConnection"&gt;50&lt;/property&gt; &lt;/user-overrides&gt; &lt;/named-config&gt;&lt;/c3p0-config&gt; Druid 导入jar包 定义配置文件druid.properties 加载配置文件 获取连接池对象 DruidDataSourceFactory.createDataSource(pro); 获取连接对象 实践 定义工具类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677import com.alibaba.druid.pool.DruidDataSourceFactory;import javax.sql.DataSource;import java.io.InputStream;import java.sql.Connection;import java.sql.ResultSet;import java.sql.SQLException;import java.sql.Statement;import java.util.Properties;/** * Druid连接池工具类 */public class JDBCUtils &#123; private static DataSource ds; static &#123; try &#123; Properties pro = new Properties(); InputStream is = DruidDemo.class.getClassLoader().getResourceAsStream("druid.properties"); pro.load(is); ds = DruidDataSourceFactory.createDataSource(pro); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; /** * 获取连接对象 */ public static Connection getConnection() throws SQLException &#123; return ds.getConnection(); &#125; /** * DML，DDL释放资源 */ public static void close(Statement stmt, Connection conn) &#123; close(null, stmt, conn); &#125; /** * DQL释放资源 */ public static void close(ResultSet rs, Statement stmt, Connection conn) &#123; if (rs != null) &#123; try &#123; rs.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; if (stmt != null) &#123; try &#123; stmt.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; if (conn != null) &#123; try &#123; conn.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; &#125; /** * 获取连接池方法 */ public static DataSource getDataSource() &#123; return ds; &#125;&#125; druid.properties 1234567driverClassName=com.mysql.jdbc.Driverurl=jdbc:mysql://localhost:3306/db1username=rootpassword=rootinitialSize=5maxActive=10maxWait=3000]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql基础学习笔记]]></title>
    <url>%2F2019%2F03%2F23%2Fmysql-note-base%2F</url>
    <content type="text"><![CDATA[SQL定义结构化查询语言(Structured Query Language)简称SQL，是一种特殊目的的编程语言，是一种数据库查询和程序设计语言，用于存取数据以及查询、更新和管理关系数据库系统；同时也是数据库脚本文件的扩展名。 结构化查询语言是高级的非过程化编程语言，允许用户在高层数据结构上工作。它不要求用户指定对数据的存放方法，也不需要用户了解具体的数据存放方式，所以具有完全不同底层结构的不同数据库系统, 可以使用相同的结构化查询语言作为数据输入与管理的接口。结构化查询语言语句可以嵌套，这使它具有极大的灵活性和强大的功能。 语法 SQL语句可以单行或多行书写，以分号结尾。 使用空格和缩进来增加可读性。 mysql的SQL语句不区分大小写，但是建议关键字使用大小写。 注释 单行注释 – 注释内容，# 注释内容 多行注释 /* 注释内容 */ SQL分类 DDL 数据定义语言，用来定义数据库对象：数据库，表，列等，关键字CRTEATE, DROP, ALTER 等。 DML 数据操作语言，用来对数据表的数据记录进行增删改，关键字INSERT, DELETE, UPDATE 等。 DQL 数据查询语言，用来对数据表的数据记录进行查询，关键字SELECT, WHERE 等。 DCL 数据控制语言，用来定义数据库的访问权限和安全级别，创建用户。关键字GRANT, REVOKE 等。 DDL：操作数据库表操作数据库：CURD create retrieve：查询 update delete 使用数据库 123456789101112131415161718/* 查询数据库 */show databases; # 查询所有数据库名称SHOW CREATE DATABASE [数据库名称]; # 查询数据库创建语句/* 创建数据库 */CREATE DATABASE IF NOT EXISTS [数据库名称];CREATE DATABASE [数据库名称] CHARACTER SET GBK;create database [数据库名称] if not exists character set [字符集];/* 修改数据库 */alter database [数据库名称] character set utf8; 修改字符集/* 删除数据库 */drop database if exists [数据库名称];/* 使用数据库 */SELECT DATABASE(); # 查询当前使用的数据库名称USE [数据库名称]; 操作数据表1234567891011121314151617181920212223242526272829303132333435/* 查询表 */show tables; # 查询数据库中所有的表desc [表名]; # 查询表结构/* 创建表 */create table [表名]( 列名1 数据类型1, 列名2 数据类型2, ... 列名n 数据类型n);# 最后一列不需要加逗号（,）create table [复制的表名] like [源表名]; # 创建一张和其他表结构一致的表/* 删除表 */drop if exists [表名];/* 修改表 */# 修改表名alter table [表名] rename to [新表名];# 修改表的字符集show create table [表名];alter table [表名] character set [utf8];# 新增一列alter table [表名] add [列名] [数据类型];# 修改列名称，数据类型alter table [表名] change [列名] [新列名] [数据类型];alter table [表名] modify [列名] [新数据类型];# 删除列alert table [表名] drop [列名];alert table [表名] drop if exists [列名]; 创建表时用到的SQL数据类型：http://www.w3school.com.cn/sql/sql_datatypes.asp 1234567891011121314151617181920212223-- 练习 --USE db1;CREATE TABLE student( id INT PRIMARY KEY NOT NULL UNIQUE, stu_name VARCHAR(20) NOT NULL, age INT NOT NULL DEFAULT 18, sex VARCHAR(4) NOT NULL);CREATE TABLE student1 LIKE student;SHOW TABLES;SHOW CREATE TABLE student;DESC student;ALTER TABLE student1 RENAME TO student2;ALTER TABLE student CHARACTER SET utf8;ALTER TABLE student CHANGE sex gender BOOLEAN;ALTER TABLE student MODIFY gender VARCHAR(4);ALTER TABLE student ADD address VARCHAR(255);ALTER TABLE student DROP address;DROP TABLE IF EXISTS student2; DML：增删改数据记录123456789--- 添加记录 ---INSERT INTO [表名] (列1, 列2, ..., 列n) VALUES (值1, 值2, ..., 值n);--- 删除记录 ---DROP FROM [表名] WHERE 列名=值; # 如果不加WHERE条件，则删除表中所有数据！！！truncate [表名]; #删除表，并创建一张一样的表--- 修改记录 ---UPDATE [表名] SET 列名1=值1, 列名2=值2 WHERE 列名=值; # 如果不加WHERE条件，则修改表中所有数据！！！ 12345678--- 练习 ---INSERT INTO student (id, stu_name, age, gender) VALUES (1, '张无忌', 18, '男');INSERT INTO student (id, stu_name, age, gender) VALUES (2, '赵敏', 18, '女');INSERT INTO student (id, stu_name, age, gender) VALUES (3, '宋青书', 18, '男');SELECT * FROM student;DELETE FROM student WHERE id=3;UPDATE student SET age=15 WHERE id=2;TRUNCATE student; DQL：查询数据记录语法：1234567891011121314select 字段列表from 表名列表where 条件列表group by 分组字段having 分组之后的条件限定order by 排序limit 分页限定 基础查询123456SELECT * FROM student;SELECT name, address FROM student;SELECT distinct address FROM student; -- 去除重复查询结果SELECT distinct name, address FROM student;SELECT math + english FROM student; -- 计算列SELECT english as en FROM student; -- 起别名 条件查询 where 后面跟查询条件 条件运算符 >、&lt;、&gt;=、&lt;=、=、&lt;&gt; BETWEEN…AND… IN (集合) LIKE：模糊查询 占位符： _：单个任意字符 %：多个任意字符 IS NULL/IS NOT NULL AND 或 &amp;&amp; OR 或 || NOT 或 ! 高级查询 排序查询 语法：ORDER BY 排序字段1 排序方式1, 排序字段2 排序方式2, 排序字段3 排序方式3, …; 升序 ASC,降序 DESC，缺省 ASC。 如果有多个排序条件，前面的值一样才会比较下一个值。 聚合函数 COUNT MAX MIN SUM AVG聚合函数计算会排除null值； 解决方案：IFNULL函数。 分组查询 语法：GROUP BY 分组字段; 分组查询的字段：分组字段、聚合函数。 where和having的区别：- where在分组前限定，不满足不参与分组。having在分组后限定，不满足不被查询。 - where后不可以跟聚合函数，having可以。 分页查询 语法：LIMIT 开始的索引，每页显示的条数。 公式：每页开始的索引 = (当前页码 - 1) * 每页的条数。 不同的数据库对分页操作的实现可能不同，LIMIT适用于mysql。 123456789101112131415161718192021222324252627--- 练习 ---drop table if exists student;create table student( id int, name varchar(20), sex varchar(20), age int, address VARCHAR(20), math int, english int);INSERT INTO `student` (`id`, `name`, `sex`, `age`, `address`, `math`, `english`) VALUES('1','赵云','男','18','蜀','99','98');INSERT INTO `student` (`id`, `name`, `sex`, `age`, `address`, `math`, `english`) VALUES('2','诸葛亮','男','22','蜀','100','88');INSERT INTO `student` (`id`, `name`, `sex`, `age`, `address`, `math`, `english`) VALUES('3','周瑜','男','18','吴','95','90');INSERT INTO `student` (`id`, `name`, `sex`, `age`, `address`, `math`, `english`) VALUES('4','孙尚香','女','15','吴','88','90');INSERT INTO `student` (`id`, `name`, `sex`, `age`, `address`, `math`, `english`) VALUES('5','典韦','男','17','魏','84','63');INSERT INTO `student` (`id`, `name`, `sex`, `age`, `address`, `math`, `english`) VALUES('6','貂蝉','女','14','汉朝','72','100');SELECT * FROM student;SELECT * FROM student ORDER BY age DESC, math, english;SELECT COUNT(id) FROM student WHERE address='蜀';SELECT COUNT(id) count_id, AVG(english) avg_en, address FROM student WHERE english&gt;70 GROUP BY address HAVING COUNT(id)&gt;1;# 每页显示三条记录SELECT * FROM student LIMIT 0,3; -- 第1页SELECT * FROM student LIMIT 3,3; -- 第2页 表的约束概念：对表中的数据进行限定，保证数据的正确性，有效性，完整性。 分类： 主键约束：primary key 非空约束：not null 唯一约束：unique 外键约束：foreign key 非空约束： 创建表时候添加：字段名 数据类型 NOT NULL 创建表后添加：alter table [表名] modify [字段名] [数据类型] NOT NULL; 删除：alter table [表名] modify [字段名] [数据类型]; 唯一约束： 创建表时候添加：字段名 数据类型 UNIQUE 创建表后添加：alter table [表名] modify [字段名] [数据类型] UNIQUE; 删除：alter table [表名] modify [字段名] [数据类型]; *UNIQUE约束的字段可以有多个NULL值。 主键约束： 含义：表中记录的唯一标识，非空且唯一，一张表只有一个主键。 创建表时添加：字段名 数据类型 PRIMARY KEY 创建表后添加：alter table [表名] modify [字段名] [数据类型] primary key; 删除主键：alter table [表名] drop primary key; 自动增长：id INT PRIMARY KEY AUTO_INCREMENT 删除自动增长：alter table [表名] modify [字段名] [数据类型]; 外键约束： 创建表时添加外键：外键列,constraint 外键名 foreign key (外键列名) references 主表名(主表列名) 创建表后添加：ALTER TABLE 表名 ADD CONSTRAINT 外键名 FOREIGN KEY (外键列名) REFERENCES 主表名(主表列名); 删除外键：ALTER TABLE 表名 DROP FOREIGN KEY 外键名; *级联操作，级联更新，级联删除：ALTER TABLE 表名 ADD CONSTRAINT 外键名 FOREIGN KEY (外键列名) REFERENCES 主表名(主表列名) ON UPDATE CASCADE ON DELETE CASCADE; 12345678910111213141516171819202122232425262728293031323334--- 练习 ---DROP TABLE IF EXISTS department;DROP TABLE IF EXISTS employee;CREATE TABLE department( id INT PRIMARY KEY AUTO_INCREMENT, NAME VARCHAR(20) NOT NULL UNIQUE, location VARCHAR(20) NOT NULL);CREATE TABLE employee( id INT PRIMARY KEY AUTO_INCREMENT, NAME VARCHAR(20) NOT NULL UNIQUE, age INT NOT NULL, dep_id INT, CONSTRAINT emp_dept_fk FOREIGN KEY (dep_id) REFERENCES department(id));INSERT INTO department VALUES(NULL, '研发部', '广州'),(NULL, '销售部', '深圳');INSERT INTO employee(NAME, age, dep_id) VALUES ('张三', 20, 1);INSERT INTO employee(NAME, age, dep_id) VALUES ('李四', 21, 1);INSERT INTO employee(NAME, age, dep_id) VALUES ('王五', 20, 1);INSERT INTO employee(NAME, age, dep_id) VALUES ('老王', 20, 2);INSERT INTO employee(NAME, age, dep_id) VALUES ('大王', 22, 2);INSERT INTO employee(NAME, age, dep_id) VALUES ('小王', 18, 2);SELECT * FROM employee;SELECT * FROM department;DROP TABLE department; --错误INSERT INTO employee(NAME, age, dep_id) VALUES ('王炸', 18, 5); --错误ALTER TABLE employee DROP FOREIGN KEY emp_dept_fk;ALTER TABLE employee ADD CONSTRAINT emp_dept_fk FOREIGN KEY (dep_id) REFERENCES department(id) ON UPDATE CASCADE ON DELETE CASCADE; 数据库的设计多表之间的关系 一对一： 举例：人和身份 分析：一个人只有一个身份证，一个身份证只对应一个人。 一对多： 举例：部门和员工 分析：一个部门有多个员工，一个员工只对应一个部门。 多对多： 举例学生和课程 分析：一个学生可以学多门课，一门课可以多个学生学。 关系实现 一对多（多对一）： 如：部门和员工 实现方式：在多的一方建立外键，指向一的主键。 多对多： 如：学生和课程 实现方式：建立中间表，至少有两个字段作为外键，分别指向两张表的主键。 一对一： 如：人和身份 实现方式：在任意一方添加唯一外键，指向另一方的主键。 数据库设计范式概念：设计关系数据库时，遵从不同的规范要求，设计出合理的关系型数据库，这些不同的规范要求被称为不同的范式，各种范式呈递次规范，越高的范式数据库冗余越小。目前关系数据库有六种范式：第一范式（1NF）、第二范式（2NF）、第三范式（3NF）、巴斯-科德范式（BCNF）、第四范式(4NF）和第五范式（5NF，又称完美范式）。 分类 第一范式（1NF）：每一列都是不可分割的原子数据项。 第二范式（2NF）：在1NF的基础上，非码属性必须完全依赖于候选码（在1NF基础上消除非主属性对主码的部分函数依赖）。 函数依赖：A–&gt;B，如果通过A属性（属性组）可以确定唯一B属性的值，则B依赖于A。 比如：学号–&gt;姓名，（学号，课程）–&gt;分数 完全函数依赖：如果A是一个属性组，B属性值的确定需要依赖于A属性组中所有的属性值。 比如：（学号，课程）–&gt;分数 部分函数依赖：如果A是一个属性组，B属性值的确定需要依赖于A属性组中部分属性值。 比如：（学号，课程）–&gt;姓名 传递函数依赖：如果B完全依赖于A，C完全依赖于B，则C传递依赖于A 比如：学号–&gt;系名，系名–&gt;系主任 码：如果在一张表中，一个属性（属性组）被其他所有属性完全依赖，则称这个属性（属性组）为该表的码。 主属性：属于码的属性 非主属性：码以外的属性 第三范式（3NF）：在2NF基础上，任何非主属性不依赖于其它非主属性（在2NF基础上消除传递依赖）。 案例学生信息：学号，姓名，年龄，系，系主任，课程名，分数 1NF（学号，姓名，年龄，系，系主任，课程名，分数） 2NF（学号）–&gt;（姓名、年龄、性别、系、系主任）（学号，课程名称）–&gt;（分数） 3NF（学号）–&gt;（姓名、年龄、性别、系）（系）–&gt;（系主任）（学号，课程名称）–&gt;（分数） 数据库的备份和还原 命令行 备份：mysqldump -u 用户名 -p 备份数据库名称 &gt; 保存路径/备份文件名.sql 还原：1. 登录mysql 2. 创建数据库 3. 使用数据库 4. 执行文件。source 备份文件 使用图形工具 多表查询内连接查询 显式内连接： 语法：select 字段 from 表1 inner join 表2 on 条件; 含义：获取两表条件相匹配的记录 隐式内连接：用where条件消除无用数据 外连接查询 左外连接 语法：select 字段列表 from 表1 left [outer] join 表2 on 条件; 含义：获取左表所有记录，即使右表没有对应匹配的记录 右外连接 语法：select 字段列表 from 表1 right [outer] join 表2 on 条件; 含义：获取右表所有记录，即使左表没有对应匹配的记录 子查询概念：查询中嵌套查询，嵌套查询称为子查询子查询的不同情况： 子查询结果是单行单列的，子查询作为条件，使用运算符：> &gt;= &lt; &lt;= = 子查询结果是多行单列的，子查询作为条件，使用运算符：in 子查询结果是多行多列的，子查询可以作为一张虚拟表 练习123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104-- 准备-- 创建数据库DROP DATABASE IF EXISTS db2;CREATE DATABASE db2 CHARACTER SET utf8;USE db2;-- 创建表DROP TABLE IF EXISTS department;DROP TABLE IF EXISTS employee;CREATE TABLE department( id INT PRIMARY KEY, NAME VARCHAR(20) NOT NULL, location VARCHAR(20) NOT NULL);CREATE TABLE employee( id INT PRIMARY KEY, NAME VARCHAR(20) NOT NULL, salary DOUBLE NOT NULL, join_date DATE NOT NULL, dep_id INT, CONSTRAINT emp_dep_fk FOREIGN KEY (dep_id) REFERENCES department(id));-- 插入数据INSERT INTO department VALUES(1, '研发部', '广州'), (2, '销售部', '广州'), (3, '财务部', '深圳');INSERT INTO employee (NAME, salary, join_date, dep_id) VALUES ('孙悟空', 7200, '2015-10-01', 1);INSERT INTO employee (NAME, salary, join_date, dep_id) VALUES ('猪八戒', 6000, '2016-03-01', 1);INSERT INTO employee (NAME, salary, join_date, dep_id) VALUES ('唐僧', 9500, '2014-05-01', 2);INSERT INTO employee (NAME, salary, join_date, dep_id) VALUES ('沙悟净', 5200, '2016-12-01', 2);INSERT INTO employee (NAME, salary, join_date, dep_id) VALUES ('白龙马', 4500, '2015-11-01', 3);-- 使得两表主键自增ALTER TABLE employee DROP FOREIGN KEY emp_dep_fk;ALTER TABLE department MODIFY id INT AUTO_INCREMENT;ALTER TABLE employee ADD CONSTRAINT emp_dep_fk FOREIGN KEY (dep_id) REFERENCES department(id) ON UPDATE CASCADE ON DELETE CASCADE;ALTER TABLE employee MODIFY id INT AUTO_INCREMENT;-- 内连接查询-- 查询所有员工的部门信息-- 隐式SELECT t1.`name`, t2.`name`FROM employee t1, department t2WHERE t1.`dep_id` = t2.`id`; -- 显式SELECT t1.`name`, t2.`name`FROM employee t1 INNER JOIN department t2ON t1.`dep_id` = t2.`id`;-- 外连接查询-- 新来一个员工，但是还没有部门INSERT INTO employee (NAME, salary, join_date) VALUES ('白骨精', 7000, '2019-03-24');-- 查询所有员工的信息以及部门信息SELECT t1.*, t2.`name`FROM employee t1 LEFT OUTER JOIN department t2ON t1.`dep_id` = t2.`id`;-- 子查询-- 查询工资最高员工的信息SELECT * FROM employee WHERE salary = (SELECT MAX(salary) FROM employee);-- 查询财务部和研发部所有员工的信息SELECT *FROM employeeWHERE dep_id IN (SELECT id FROM department WHERE NAME IN ('财务部', '研发部'));-- 查询工资高于平均工资员工的名字,工资和部门SELECT t1.`name`, t1.`salary`, t2.`name`FROM employee t1 LEFT JOIN department t2ON t1.`dep_id` = t2.`id`WHERE salary &gt; (SELECT AVG(salary) FROM employee); -- 查询入职日期是2017年以前员工的信息(包括部门信息)\-- 找出2017年以前入职员工的信息，再和department表内连接SELECT t_d.`name`, t_e.*FROM department t_d, (SELECT * FROM employee WHERE join_date &lt; '2017-01-01') t_eWHERE t_d.`id` = t_e.`dep_id`; -- 先内连接再where判断 事务事务的基本介绍概念：如果一个包含多个步骤的业务操作，被一个事务管理，要么同时成功，要么同时失败。举例：张三转账500元给李四，1.张三余额&gt;500；2.张三金额-500；3.李四金额+500操作： 开启事务 提交 回滚 12345678910111213141516171819202122232425262728293031DROP DATABASE IF EXISTS db3;CREATE DATABASE IF NOT EXISTS db3 DEFAULT CHARSET utf8 COLLATE utf8_general_ci;USE db3;CREATE TABLE account( id INT PRIMARY KEY AUTO_INCREMENT, NAME VARCHAR(20) NOT NULL, balance DOUBLE NOT NULL);INSERT INTO account (NAME, balance) VALUES('张三', 1000);INSERT INTO account (NAME, balance) VALUES('李四', 1000);UPDATE account SET balance = 1000 WHERE NAME = '张三';UPDATE account SET balance = 1000 WHERE NAME = '李四';SELECT * FROM account;-- 张三转500元给李四-- 0. 开启事务START TRANSACTION;-- 1. 业务语句UPDATE account SET balance = balance - 500 WHERE NAME = '张三';UPDATE account SET balance = balance + 500 WHERE NAME = '李四';-- 2. 提交事务COMMIT;-- 3. 失败回滚ROLLBACK; mysql中事务默认自动提交。 自动提交：在mysql中，一条DML（增删改）语句默认提交一次事务。 手动提交：需要先开启事务，再提交（commit），开启事务不commit，DML执行回滚。 查看事务的默认提交方式：SELECT @@autocommit; – 1 自动提交，0 手动提交 修改事务的默认提交方式：SET @@autocommit = 0; 事务的四大特征(ACID) 原子性：是不可分割的最小操作单位，要么同时成功，要么同时失败。 持久性：当事务提交或回滚后，数据库会持久化保存数据。 隔离性：多个事务之间，相互独立。 一致性：事务操作前后，数据总量不变。 事务的隔离级别概念：多个事务之间隔离的，但是多个事务操作同一批数据，会引发一些问题，设置不同的隔离级别可以解决问题。 存在的问题： 脏读：一个事务，读取到另一个事务中没有提交的数据。 不可重复读：同一个事务中，两次读取到的数据不同。 幻读：一个事务操作（DML）数据表中所有记录，另一个事务添加了一条数据，第一个事务则查询不到自己的修改 隔离级别： read uncommitted：读未提交 产生的问题：脏读、不可重复读、幻读 read committed：读已提交（Oracle默认） 产生的问题：不可重复读、幻读 repeatable read：可重复读（mysql默认） 产生的问题：幻读 serializable：串行化 可以解决所有的问题 * 注意：隔离级别从小到大安全性越来越高，但是效率越来越低。 查询隔离级别：select @@tx_isolation; 设置隔离级别：SET GLOBAL TRANSACTION ISOLATION LEVEL READ COMMITTED; 用户权限管理DCL管理用户123456789101112131415161718192021222324252627282930313233-- 查询用户USE msyql;SELECT * FROM USER;-- 添加用户CREATE USER '用户名'@'主机名' IDENTIFIED BY '密码';-- 删除用户DROP USER '用户名'@'主机名';-- 修改密码UPDATE USER SET PASSWORD=PASSWORD('新密码') WHERE USER='用户名';SET PASSWORD FOR '用户名'@'主机名' = PASSWORD('新密码');/*忘记root密码？1. 停止mysql服务2. 使用无验证方式启动mysql3. 无密码登录mysql，修改密码4. 重启mysql服务，以新密码登录*/msyqld --skip-grant-tablesmysql-- 查询用户权限SHOW GRANTS FOR '用户名'@'主机名';-- 授予权限GRANT 权限列表 ON 数据库名.表名 TO '用户名'@'主机名';GRANT ALL PRIVILEGES ON *.* TO 'root'@'localhost' WITH GRANT OPTION;-- 撤销用户权限REVOKE 权限列表 ON 数据库名.表名 FROM '用户名'@'主机名';]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java-commons-fileupload]]></title>
    <url>%2F2019%2F01%2F22%2Fjava-commons-fileupload%2F</url>
    <content type="text"><![CDATA[原文地址：http://commons.apache.org/proper/commons-fileupload/index.html 概览Commons FileUpload 让添加健壮、高性能的文件上传功能到你的servlet和web应用程序中变得十分容易。 FileUpload解析符合RFC 1867（HTML中基于表单的文件上传）的请求。就是说，如果一个HTTP请求，是用POST方法提交的，并且内容类型为“multipart/form-data”，FileUpload就可以解析这个请求，并且让结果易于调用者使用。 从1.3版本开始，FileUpload处理RFC 2047编码的header值。发送一个multipart/form-data请求到服务器最简单的方式是通过web表单，即：123456&lt;form method="POST" enctype="multipart/form-data" action="fup.cgi"&gt; File to upload: &lt;input type="file" name="upfile"&gt;&lt;br/&gt; Notes about the file: &lt;input type="text" name="note"&gt;&lt;br/&gt; &lt;br/&gt; &lt;input type="submit" value="Press"&gt; to upload the file!&lt;/form&gt; 使用FileUploadFileUpload可以有许多用法，看你应用的需要。最简单的，你可以调用一个独立的方法解析servlet请求，然后处理适用于程序的对象列表。另一方面，你可能决定自定义FileUpload来完全控制各个对象的存储方式，比如，你决定将内容流传输到数据库。 在这里，我们将介绍FileUpload的基本原理，并说明一些简单的、最常见的使用模式。自定义FileUpload将在别处说明。 FileUpload依赖于Commons IO，因此确保在类路径中有依赖页提到的Commons IO版本。 如何工作文件上传请求包含了一个根据RFC 1867编码的有序item列表。FileUpload可以解析请求，并且向你的应用提供单文件上传item的列表。无论其底层如何，每个item都实现了FileItem接口。 本文描述了commons fileupload库的传统API。传统API是一个便捷的方法，但是为了追求更佳的性能，你会更喜欢Stream API。 每个文件item拥有许多你的应用会涉及到的属性。举例，每个item有名称和内容类型，可以提供InputStream获取它的数据。另一方面，你可能需要分别处理item，取决于item是否是常规的表单字段——就是说，数据是来自普通的文本框或类似的HTML字段，或者是一个上传的文件。FileItem接口提供了判定方法，并且以最合适的方式获取数据。 FileUpload用FileItemFactory来创建新的文件item。这就是FileUpload最大的灵活性。工厂最终控制每个item的创建方式。FileUpload附带的工厂实现存储item数据到内存或磁盘中，这取决于item的大小（比如数据的字节）。但是，可以自定义此行为以适合您的应用程序。 Servlets 和 Portlets从1.1版本开始，FileUpload支持servlet和porlet环境中的文件上传请求。在两个环境中的用法几乎相同，因此本文档的其余部分仅涉及servlet环境。 如果要构建portlet应用程序，以下是在阅读本文档时应该注意两个区别： 在您看到对ServletFileUpload类的引用，请替换为PortletFileUpload类。 在您看到对HttpServletRequest类的引用，请替换为ActionRequest类。 解析请求在处理上传的item之前，你需要解析请求。确保是请求是文件上传请求很简单，FileUpload提供了一个静态方法。 12// Check that we have a file upload requestboolean isMultipart = ServletFileUpload.isMultipartContent(request); 现在我们准备将请求解析为item组成。 最简单的示例最简单的使用方案如下： 相当小的上传item应该被保存在内存中 较大的item应该被写入到磁盘的临时文件中 不应允许非常大的文件上传请求 要保存在内存中的item文件的默认最大值、允许上传请求的最大值和临时文件的位置是合适的 这种处理请求的方案可能不是最简单的： 12345678910111213// Create a factory for disk-based file itemsDiskFileItemFactory factory = new DiskFileItemFactory();// Configure a repository (to ensure a secure temp location is used)ServletContext servletContext = this.getServletConfig().getServletContext();File repository = (File) servletContext.getAttribute("javax.servlet.context.tempdir");factory.setRepository(repository);// Create a new file upload handlerServletFileUpload upload = new ServletFileUpload(factory);// Parse the requestList&lt;FileItem&gt; items = upload.parseRequest(request); 这就是所有要做的，真的。 解析结果是一个文件item的List，它的每个元素实现了FileItem接口。接下来讨论处理item。 实践更多的控制如果你的使用方案和上面提到最简单的例子相近，但是你需要一些更多的控制，你可以自定义上传处理程序或者文件item工厂。下面的例子展示了几个配置项： 123456789101112131415// Create a factory for disk-based file itemsDiskFileItemFactory factory = new DiskFileItemFactory();// Set factory constraintsfactory.setSizeThreshold(yourMaxMemorySize);factory.setRepository(yourTempDirectory);// Create a new file upload handlerServletFileUpload upload = new ServletFileUpload(factory);// Set overall request size constraintupload.setSizeMax(yourMaxRequestSize);// Parse the requestList&lt;FileItem&gt; items = upload.parseRequest(request); 当然，每种配置方法都独立于其他配置方法。但是如果你想一次性配置工厂，你可以用构造函数来完成，像这样： 12// Create a factory for disk-based file itemsDiskFileItemFactory factory = new DiskFileItemFactory(yourMaxMemorySize, yourTempDirectory); 如果你想更多地控制请求解析过程，比如存储item到其他位置——数据库中，你可以查看自定义FileUpload。 处理要上传的item一旦解析完成，你会得到一个待处理文件item的List。大多数情况下，你会想要从常规的表单字段中分别处理文件上传，因此，你可能像这样处理list： 1234567891011// Process the uploaded itemsIterator&lt;FileItem&gt; iter = items.iterator();while (iter.hasNext()) &#123; FileItem item = iter.next(); if (item.isFormField()) &#123; processFormField(item); &#125; else &#123; processUploadedFile(item); &#125;&#125; 对一个常规的表单字段，你很可能只对item的名称和String值感兴趣。如你所愿，处理这些非常简单： 123456// Process a regular form fieldif (item.isFormField()) &#123; String name = item.getFieldName(); String value = item.getString(); ...&#125; 对文件上传，在处理内容前，有几个不同的事情你可能需要了解线下。这有一个你会感兴趣的方法示例： 123456789// Process a file uploadif (!item.isFormField()) &#123; String fieldName = item.getFieldName(); String fileName = item.getName(); String contentType = item.getContentType(); boolean isInMemory = item.isInMemory(); long sizeInBytes = item.getSize(); ...&#125; 对于上传的文件，您通常不希望通过内存访问它们，除非它们很小，或者除非您没有其他选择。相反，您需要将内容作为流处理，或将整个文件写入其最终位置。 FileUpload提供了完成这两者的简单方法。 123456789// Process a file uploadif (writeToFile) &#123; File uploadedFile = new File(...); item.write(uploadedFile);&#125; else &#123; InputStream uploadedStream = item.getInputStream(); ... uploadedStream.close();&#125; 注意，FileUpload的默认实现，write()会尝试重命名文件为指定目标，如果数据已经在临时文件中。实际上只有因为某些原因重命名失败或者数据已经在内存中，才会复制数据。 如果确实需要访问内存中的上传数据，只需调用get（）方法即可将数据作为字节数组获取。 12// Process a file upload in memorybyte[] data = item.get(); 资源清理本节仅适用于使用DiskFileItem的情况。换句话说，如果您上传的文件在处理之前写入临时文件，则适用。 这些临时文件会自动删除，如果它们不再被使用（更确切地，DiskFileItem实例是垃圾回收，这是由org.apache.commons.io.FileCleanerTracker类悄悄完成的，它启动了一个收割线程）。 如果不再需要，则应停止此收割者线程。在servlet环境中，这是通过使用名为FileCleanerCleanup的特殊servlet上下文侦听器来完成的。为此，请在web.xml中添加如下部分： 123456789&lt;web-app&gt; ... &lt;listener&gt; &lt;listener-class&gt; org.apache.commons.fileupload.servlet.FileCleanerCleanup &lt;/listener-class&gt; &lt;/listener&gt; ...&lt;/web-app&gt; 创建 DiskFileItemFactoryFileCleanerCleanup提供了org.apache.commons.io.FileCleaningTracker的实例。创建org.apache.commons.fileupload.disk.DiskFileItemFactory时必须使用此实例。这应该通过调用如下方法来完成：12345678910public static DiskFileItemFactory newDiskFileItemFactory(ServletContext context, File repository) &#123; FileCleaningTracker fileCleaningTracker = FileCleanerCleanup.getFileCleaningTracker(context); DiskFileItemFactory factory = new DiskFileItemFactory(DiskFileItemFactory.DEFAULT_SIZE_THRESHOLD, repository); factory.setFileCleaningTracker(fileCleaningTracker); return factory;&#125; 禁用清除临时文件要禁用对临时文件的跟踪，可以将FileCleaningTracker设置为null。因此，将不再跟踪创建的文件。特别是，它们将不再自动删除。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven5分钟快速入门]]></title>
    <url>%2F2019%2F01%2F09%2Fjava-maven-in-five-minutes%2F</url>
    <content type="text"><![CDATA[简介Apache Maven是一个软件项目管理和理解工具。基于项目对象模型（POM）的概念，Maven可以从中心信息来管理项目的构建、报告和文档。 下载下载链接：http://maven.apache.org/download.cgi可以选zip和tar.gz包下载。 安装 Maven是一个java工具，系统必须先安装java。Maven安装过程非常简单：解压压缩包，添加包含mvn命令的bin目录到环境变量PATH即可。 具体步骤： 确保JAVA_HOME环境变量已经设置，并且正确指向了JDK的安装目录； 在maven安装目录下解压压缩包unzip apache-maven-3.6.0-bin.zip； 解压后得到apache-maven-3.6.0目录，将其中的bin目录添加到环境变量PATH中。 在cmd/shell中输入mvn -v，看到maven版本信息，确认安装成功。 123456# mvn -v输出Apache Maven 3.6.0 (97c98ec64a1fdfee7767ce5ffb20918da4f719f3; 2018-10-25T02:41:47+08:00)Maven home: D:\Program\apache-maven-3.6.0\bin\..Java version: 1.8.0_161, vendor: Oracle Corporation, runtime: D:\Program Files\Java\jdk1.8.0_161\jreDefault locale: zh_CN, platform encoding: GBKOS name: "windows 10", version: "10.0", arch: "amd64", family: "windows" 创建项目在你准备放置项目的目录中运行shell，执行如下命令： 1mvn archetype:generate -DgroupId=com.mycompany.app -DartifactId=my-app -DarchetypeArtifactId=maven-archetype-quickstart -DarchetypeVersion=1.4 -DinteractiveMode=false -X 如果你是刚装完maven，第一次运行会花费一些时间，这是因为maven正在下载最新的jar包和其他文件到本地仓库中。你可能需要多执行几次命令，才会成功。这是因为在完成所有的下载前，远程服务器有可能超时。 你会发现命令创建了一个和artifactId名称相同的目录。进入该目录 1cd my-app my-app的目录结构如下：123456789101112131415my-app|-- pom.xml`-- src |-- main | `-- java | `-- com | `-- mycompany | `-- app | `-- App.java `-- test `-- java `-- com `-- mycompany `-- app `-- AppTest.java src/main/java包含了项目的源代码，src/test/java包含了测试代码，pom.xml文件是项目的项目对象模型POM。 标准的项目结构参考这个链接：http://maven.apache.org/guides/introduction/introduction-to-the-standard-directory-layout.html POMMaven中的pom.xml文件是项目的核心配置。它是一个单一的配置文件，包含了以你想要的方式来构建项目所需要的大部分信息。POM是庞大的，其复杂性可能让人望而生畏，但是在有效地使用它之前，没必要了解所有的复杂结构。项目的POM是这样： 1234567891011121314151617181920212223# pom.xml&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.mycompany.app&lt;/groupId&gt; &lt;artifactId&gt;my-app&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.7&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.7&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 我刚刚做了些什么您执行了Maven目标archetype：generate，并将各种参数传递给该目标。前缀archetype的参数是提供了目标的插件plugin。如果你熟悉Ant，你会觉得这和任务很类似。archetype:generate目标创建了一个基于maven-archetype-quickstart archetype的项目。我想说的是，一个plugin是一系列具有共同目标的goal。比如jboss-maven-plugin的目标是处理各种jboss项目。 构建项目1mvn package 命令行会打印出各种操作，并以如下结尾：12345678...[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESSFUL[INFO] ------------------------------------------------------------------------[INFO] Total time: 2 seconds[INFO] Finished at: Thu Jul 07 21:34:52 CEST 2011[INFO] Final Memory: 3M/6M[INFO] ------------------------------------------------------------------------ 与执行的第一个命令（archetype：generate）不同，您可能会注意到第二个命令只是一个单词 - package。和goal不同，这是一个phase。phase是构建生命周期中的一个步骤，它们是一个有序的阶段队列。当给出一个阶段时，Maven将执行序列中的每个阶段，直到并包括一开始定义的阶段。例如，如果我们执行编译阶段，那么实际执行的阶段就是： validate generate-sources process-sources generate-resources process-resources compile 您可以使用以下命令测试新编译和打包的JAR：1java -cp target/my-app-1.0-SNAPSHOT.jar com.mycompany.app.App 这会打印：Hello World！ 运行Maven工具Maven阶段虽然不是一个全面的列表，但这些是最常见的默认生命周期阶段。 validate：验证项目是否正确，并提供所有必要信息 compile：编译项目的源代码 test：使用合适的单元测试框架测试编译的源代码。这些测试不需要被打包或部署 package：获取已编译的代码并将其打包为可分发的格式，例如JAR integration-test：如有必要，将程序包处理并部署到可以运行集成测试的环境中 verify：运行所有检查以验证包是否有效并符合质量标准 install：将软件包安装到本地存储库中，以便在本地用作其他项目的依赖项 deploy：在集成或发布环境中完成，将最终包复制到远程存储库以与其他开发人员和项目共享 除了上面的默认列表之外，还有另外两个Maven生命周期。他们是： clean：清除先前构建创建的工件 site：为该项目生成站点文档 阶段实际上被映射到底层的各个目标。每个阶段执行的特定目标取决于项目的包装类型。例如，如果项目类型是JAR，则包执行jar：jar，如果项目类型是war，则执行war：war。值得注意的一点是，阶段和目标可以按顺序执行。 12# 此命令将清理项目，复制依赖项并打包项目。mvn clean dependency:copy-dependencies package 生成站点文档12# 此阶段根据项目的pom信息生成一个站点。您可以查看target / site下生成的文档mvn site 总结我们希望这个快速入门可以引起你对Maven的兴趣。这是一个非常简短的快速入门指南，你已经做好了解刚刚所有操作更详细信息的准备。参考Maven入门指南]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[log4j——java日志框架]]></title>
    <url>%2F2018%2F12%2F31%2Fjava-logging-log4j%2F</url>
    <content type="text"><![CDATA[原文地址：http://logging.apache.org/log4j/1.2/manual.html 摘要本文档描述了log4j的API，它的特性和设计原理。Log4j是一个基于众多作者成果的开源项目。它允许开发者控制以任意粒度输出日志语句。它在运行时可以使用外部配置文件进行完全配置。最棒的是，log4j有一个平滑的学习曲线。注意：从用户的反馈看，它也很容易上瘾。 引言几乎所有的大型应用都包含了它自身的日志或者跟踪API。根据这条规则，在1996年初E.U. SEMPER项目决定编写自己的跟踪API。经过无数次的改进、几次改版和众多工作，这些API演变成了log4j,一个受欢迎的java日志包。这个软件包在Apache软件许可证下发行。Apache 软件许可证是一个经open source认证完全成熟的开源许可证。最新的log4j版本，包含全部源代码、class文件和文档可以在http://logging.apache.org/log4j/找到。顺便说一句，log4j已被移植到C，C ++，C＃，Perl，Python，Ruby和Eiffel语言。 在代码中插入日志语句是调试代码的一种低技术含量方法。这可能也是唯一的方法，因为调试器总会有不可用和不适用的时候。多线程应用和分布式应用通常就是这种情况。 经验表明，日志是开发周期中的一个重要组成部分。日志有几个优点。它提供了有关应用运行的精确上下文。日志预计一旦插入到代码，日志的输出生成就不需要人为干预。而且，日志输出可以保持在持久介质中以便日后研究。除了在开发周期使用以外，一个足够丰富的日志包可以被视为审计工具。 正如Brian W. Kernighan和Rob Pike在他们的优秀著作《编程实践》中所说： As personal choice, we tend not to use debuggers beyond getting a stack trace or the value of a variable or two. One reason is that it is easy to get lost in details of complicated data structures and control flow; we find stepping through a program less productive than thinking harder and adding output statements and self-checking code at critical places. Clicking over statements takes longer than scanning the output of judiciously-placed displays. It takes lesstime to decide where to put print statements than to single-step to the critical section of code, even assuming we know where that is. More important, debugging statements stay with the program;debugging sessions are transient. 日志记录也有缺点，它会拖慢应用的速度。如果过于冗余，它会引发盲目地回滚。为了缓解这些问题，log4j被设计为可靠、快速和可扩展的。由于日志记录并不是应用程序的主要关注点，log4j API力求易于理解和使用。 Loggers, Appenders和LayoutsLog4j有三个主要组件：logger，appenders和layouts。这三类组件协同工作，使开发者能根据消息类型和级别在运行时控制这些消息的输出格式和位置。 Logger的层次结构任何日志API优于System.out.println最明显也是最重要的地方在于，它们可以禁用某些日志语句，同时运行其他语句打印不受影响。假定了日志空间，即所有可能的日志语句的空间的功能可以根据开发者的某些选择条件进行分类。作为软件包的核心理念，它很有前瞻性地让我们选择分类。然而，从1.2版本以后，Logger类已经取代了Category类。对于熟悉log4j早期版本的人来说，Logger类可以被视为Category类的别名。 Logger是有名称的实体。Logger的名称区分大小写，遵循分层命名规则： 如果跟在一个“.”号后面的logger名称是后代logger名称的前缀，这个logger被称作另个一个logger的祖先。如果在logger和它的后代logger之间没有祖先，则称这个logger是子logger的父代。 举个例子，叫做“com.foo”的logger是“com.foo.Bar”logger的父亲。相似地，“java”是“java.util”和“java.util.Vector”的祖先。大多数开发者都很熟悉这种命名方案。 root logger是logger级别中的最高级，它有以下2点特征： 总是存在 无法通过名称检索 调用静态方法Logger.getRootLogger可以检索root logger。其他的logger可以通过Logger.getLogger方法实例化和检索。此方法将想要的logger作为参数。Logger的一些基础的方法如下： 123456789101112131415161718package org.apache.log4j;public class Logger &#123; // Creation &amp; retrieval methods: public static Logger getRootLogger(); public static Logger getLogger(String name); // printing methods: public void trace(Object message); public void debug(Object message); public void info(Object message); public void warn(Object message); public void error(Object message); public void fatal(Object message); // generic printing method: public void log(Level l, Object message);&#125; 可以给logger分配等级，可用的等级有： TRACE DEBUG INFO WARN ERROR FATAL 这些都被定义在org.apache.log4j.Level类中。尽管我们不推荐您这么做，你可以通过定义Level的子类定义自己的等级。稍后将讲述一个更好的方法。 如果给定的logger没有分配级别，那么它将从具有指定级别的最近祖先继承一个级别。更正式的说： 一个给定的logger C的继承等级，等于logger层次结构中的第一个非空级别，从C开始并且向上追溯直到root logger。 为确保所有logger最终都能继承一个级别，root logger始终具有指定的级别。 下面是四个表，其中包含各种已分配的级别值以及根据上述规则生成的继承级别。 日志记录请求通过调用logger实例的一种打印方法来实现。打印方法有debug, info, warn, error, fatal, log。 根据定义，打印方法确定日志记录请求的级别。例如，如果c是logger实例，则语句c.info（“..”）是级别INFO的记录请求。 如果日志记录请求的级别高于或等于其logger的级别，则称其是已启用的。否则，该请求被禁用。没有指定级别的logger将从层次结构中继承一个级别。该规则总结如下： 在级别q的logger（被指定的或者继承的，以实际为准）中，进行级别p的记录请求，如果p&gt;=q，则该记录请求被启用。 该规则是log4j的核心。log4j指定的基本是有序的。对标准的级别，排序是DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL。 这是一个该规则的示例。 123456789101112131415161718192021222324// get a logger instance named "com.foo"Logger logger = Logger.getLogger("com.foo");// Now set its level. Normally you do not need to set the// level of a logger programmatically. This is usually done// in configuration files.logger.setLevel(Level.INFO);Logger barlogger = Logger.getLogger("com.foo.Bar");// This request is enabled, because WARN &gt;= INFO.logger.warn("Low fuel level.");// This request is disabled, because DEBUG &lt; INFO.logger.debug("Starting search for nearest gas station.");// The logger instance barlogger, named "com.foo.Bar",// will inherit its level from the logger named// "com.foo" Thus, the following request is enabled// because INFO &gt;= INFO.barlogger.info("Located nearest gas station.");// This request is disabled, because DEBUG &lt; INFO.barlogger.debug("Exiting gas station search"); 调用相同名称的getlogger方法总会返回相同logger对象的引用。例如， 12Logger x = Logger.getLogger("wombat");Logger y = Logger.getLogger("wombat"); x,y指向了相同的logger对象。 因此，可以配置一个logger，然后在代码中检索相同的实例，而不用传递引用。和生物学的父子关系（父母总是先于孩子）不同，log4j可以以任意顺序创建和配置logger。特别地，父logger会查找并链接到其后代，即使父logger在后代logger之后被实例化。 log4j的环境配置通常在程序初始化时完成。更好的方法是读取一个配置文件。这个方法很快会介绍。 log4j使得通过程序组件命名logger非常简单。这可以通过在每个类中静态实例化一个logger完成，logger名称等于该类的完全限定名称。这是一个非常有效且直截了当的定义logger的方法。由于日志输出带有生成日志logger的名称，这种命名策略可以轻松识别日志消息的来源。但是，这只是一个可能的logger命名策略，尽管很常见。log4j不限制logger的名称，开发者可以根据需要自由命名。 尽管如此，遵循logger所在的类命名logger似乎是目前已知的最佳策略。 Appenders and Layouts基于logger，选择性地启用或禁用日志记录请求只是一部分。log4j允许日志记录请求打印到多个目标。在log4j中，输出目的地被称作appender。当前，存在控制台、文件、GUI组件、远程套接字服务器、JMS、NT Event Loggers和远程UNIX Syslog守护程序的appender。它也可以异步记录。 一个logger可以链接多个appender。 addAppender方法添加一个appender到给定的logger中。一个给定logger中，每个启用的日志记录请求会被转发给它所有的appender以及更高层次结构logger的appender。换句话说，appender可以从logger层级结构中额外被继承。比如，一个控制台appender被添加到root logger，所以所有启用的日志记录请求至少被打印到控制台。如果添加一个文件appender到一个叫做C的logger中，C和C的祖先logger中启用的日志记录请求会被打印到文件和控制台中。通过设置additivity标记为false，可以覆盖默认行为，从而appender不再是累积的。 有关appender可加性的规则总结如下： logger C的一条日志语句输出会到达C和C祖先的所有appender中。但是，如果一个logger C的祖先，叫做P，它的additivity标记设置为false，那么C的输出会被定向到C和C祖先（追溯到且包括P的）的所有appender中，但P的祖先不在其中。 下面的表格展示了一个示例： 通常，用户希望自定义的不仅仅是输出目的地，还有输出格式。自定义输出格式可以通过给appender关联layout实现。根据用户的期望，layout负责格式化日志记录请求，而appender负责发送格式化的输出到它的目的地。 PatternLayout，是标准log4j发行版本的一部分，它允许用户根据类似C语言printf函数的转换模式指定输出格式。 比如。转换模式为“%r [%t] %-5p %c - %m%n”的PatternLayout将进行类似于这样的输出： 176 [main] INFO org.foo.Bar - Located nearest gas station. 第一个字段是自程序启动开始已经过去的毫秒数。第二个字段是发出日志请求的线程。第三个字段是日志语句的等级。第四个字段是和日志请求相关的logger。在“-”之后的文字是语句消息。 同样重要的是，log4j根据用户指定的标准渲染日志消息的内容。比如，如果你经常要记录日志Orange，你当前项目中的一个对象类型，你可以注册一个OrangeRender，它会在Orange需要被记录时被调用。 对象渲染遵循类层次结构。举个例子，假设橙子是水果，如果你注册一个FruitRender，所有水果包括橙子都会FruitRender被渲染，当然除非你给橙子指定了OrangeRender。 配置在程序代码中插入日志请求需要相当多的规划和功夫。调查显示，大约4%的代码被专门用来记录日志。因此，即便是中等规模的程序都会在其代码中嵌入数以千计的日志记录语句。鉴于语句的数量，不用手动修改来管理日志记录语句就变得势在必行。 log4j环境可以通过编程完全配置，但是使用配置文件配置log4j就灵活的多。目前，配置文件可以用XML和Java Properties（键=值）方式配置。 让我们在一个使用log4j的假想应用程序MyApp的帮助下，看看配置是如何实现的。 1234567891011121314151617181920212223import com.foo.Bar;// Import log4j classes.import org.apache.log4j.Logger;import org.apache.log4j.BasicConfigurator;public class MyApp &#123; // Define a static logger variable so that it references the // Logger instance named "MyApp". static Logger logger = Logger.getLogger(MyApp.class); public static void main(String[] args) &#123; // Set up a simple configuration that logs on the console. BasicConfigurator.configure(); logger.info("Entering application."); Bar bar = new Bar(); bar.doIt(); logger.info("Exiting application."); &#125;&#125; MyApp首先导入log4j相关的类。然后它用MyApp类的完全限定名称定义了一个静态logger变量。 MyApp使用了定义在com.foo中的Bar类。 12345678910package com.foo;import org.apache.log4j.Logger;public class Bar &#123; static Logger logger = Logger.getLogger(Bar.class); public void doIt() &#123; logger.debug("Did it again!"); &#125; &#125; 调用BasicConfigurator.configure方法创建了一个相当简单的log4j设置。这个方法将root logger硬连线到ConsoleAppender。使用PatternLayout“%-4r [%t] %-5p %c %x - %m%n”来格式化输出。 注意，root logger默认被指定为Level DEBUG。 MyApp的输出如下： 0 [main] INFO MyApp - Entering application.36 [main] DEBUG com.foo.Bar - Did it again!51 [main] INFO MyApp - Exiting application. 下图描绘了在调用了BasicConfigurator.configure后，MyApp的对象图。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[slf4j——java日志门面]]></title>
    <url>%2F2018%2F12%2F31%2Fjava-logging-slf4j%2F</url>
    <content type="text"><![CDATA[原文地址：https://www.slf4j.org/manual.html SLF4J（Simple Logging Facade for Java）作为一个简单的门面或者抽象对象服务于各种日志框架，比如java.util.logging，logback，log4j。SLF4J允许终端用户在部署时插入想使用的日志框架。注意，在你的库/应用中启用SLF4J意味着只需添加一个叫做slf4j-api-*.jar的强依赖。 Hello World编程的传统惯例，这是一个例子，演示了使用SLF4J用最简单的方式输出“Hello World”。它开始于用名称“HelloWorld”获取一个logger对象。logger用来记录“Hello World”消息。 123456789import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class HelloWorld &#123; public static void main(String[] args) &#123; Logger logger = LoggerFactory.getLogger(HelloWorld.class); logger.info("Hello World"); &#125;&#125; 为了运行这个例子，首先你需要下载slf4j，然后解压它。解压完添加slf4j-api-*.jar文件到你的类路径中。 编译运行HelloWorld会在控制台中输出如下的结果： SLF4J: Failed to load class “org.slf4j.impl.StaticLoggerBinder”.SLF4J: Defaulting to no-operation (NOP) logger implementationSLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details. 打印警告信息的原因是在你的类路径中找不到slf4j的绑定。 一旦你添加一个绑定到你的类路径中，警告就会消失。假设你添加了slf4j-simple-1.8.0-beta2.jar，你的类路径需要包含： slf4j-api-1.8.0-beta2.jar slf4j-simple-1.8.0-beta2.jar 现在编译运行HelloWorld会在控制输入如下结果： 0 [main] INFO HelloWorld - Hello World 经典使用模式下面的示例代码演示了SLF4J的经典使用模式。注意，在第15行使用的占位符{}，更多细节参考FAQ“What is the fastest way of logging?”。 12345678910111213141516171819import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class Wombat &#123; final Logger logger = LoggerFactory.getLogger(Wombat.class); Integer t; Integer oldT; public void setTemperature(Integer temperature) &#123; oldT = t; t = temperature; logger.debug("Temperature set to &#123;&#125;. Old temperature was &#123;&#125;.", t, oldT); if(temperature.intValue() &gt; 50) &#123; logger.info("Temperature has risen above 50 degrees."); &#125; &#125;&#125; 在部署时与日志框架绑定如之前提到的，SLF4J支持各种日志框架。SLF4J发行版附带了几个叫做“SLF4J bindings”的jar文件，每个文件对应一个支持的框架。 slf4j-log4j12-1.8.0-beta2.jar广泛使用的日志框架：log4j1.2版本的绑定。你还需要把log4j.jar放到你的类路径中。 slf4j-jdk14-1.8.0-beta2.jarJDK1.4中java.util.logging的绑定 slf4j-nop-1.8.0-beta2.jarNOP的绑定，默默丢弃所有的日志。 slf4j-simple-1.8.0-beta2.jar简单日志实现的绑定，这会输出所有的事件到System.err中。只有INFO或者更高级别的消息会被打印。这种绑定往往在简单的应用中很有用。 slf4j-jcl-1.8.0-beta2.jarJakarta Commons Logging的绑定。此绑定会委派所有SLF4J日志记录到JCL。 logback-classic-1.0.13.jar (requires logback-core-1.0.13.jar)原生实现SLF4J项目外还会有SLF4J的绑定,例如，原生实现SLF4J的logback。Logback的ch.qos.logback.classic.Logger类直接实现了SLF4J的org.slf4j.Logger接口。从而，将SLF4J和logback结合使用会严格限制0内存和计算开销。 要切换日志框架，替换类路径中的slf4j绑定就可以了。举个例子，要切换java.util.logging到log4j，用slf4j-log4j12-1.8.0-beta2.jar替换slf4j-jdk14-1.8.0-beta2.jar。 SLF4J不依赖于任何特殊的类加载器。实际上，每个SLF4J绑定在编译时都是硬连线的，使用有且只有一个特定的日志框架。举个例子，slf4j-log4j12-1.8.0-beta2.jar在编译时被绑定使用log4j。在你的代码中，除了slf4j-api-1.8.0-beta2.jar，你只需要将有且只有一个你选择的绑定放到合适的类路径中。不要在类路径中放超过一个绑定。这有一个图解说明。 SLF4J的接口以及接口的各个适配器是非常简单的。大多数熟悉java语言的开发者应该有能力在一个小时内阅读和完全理解它的代码。不需要类加载器的知识，因为SLF4J不需要也无法直接访问任何类加载器。因此，SLF4J不会遇到Jakarta Commons Logging（JCL）出现的没有类加载器和内存泄露的问题。 鉴于SLF4J接口以及其部署模型的简单性，新的日志框架开发人员应该会非常容易编写SLF4J绑定。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis 基础]]></title>
    <url>%2F2018%2F12%2F22%2Fredis-base%2F</url>
    <content type="text"><![CDATA[redis数据结构 STRING LIST SET HASH ZSET STRINGGETSETDEL LISTLPUSH RPUSHLPOP RPOPLRANGELINDEX SETSADDSREMSISMEMBERSEMBERS HASHHSETHGETHGETALLHDEL ZSETZADDZRANGEZRANGEBYSCOREZREM redis命令字符串INCR keyDECR keyINCRBY key intDECRBY key intINCRBYFLOAT key float APPEND key valueGETRANGE key start endSETRANGE key offset value]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux安装tomcat]]></title>
    <url>%2F2018%2F12%2F16%2Finstall-tomcat-on-cetos%2F</url>
    <content type="text"><![CDATA[本文环境 Centos6.8 64位，安装版本 tomcat8.5.35 环境依赖tomcat运行需要jvm（java虚拟机），因此需确认系统已经安装jdk。参考文档：Linux安装jdk 如下是tomcat和jdk的版本对应关系：官网文档：http://tomcat.apache.org/whichversion.html 下载软件官网下载下载地址：https://tomcat.apache.org/download-80.cgi wget下载1wget https://www-us.apache.org/dist/tomcat/tomcat-8/v8.5.35/bin/apache-tomcat-8.5.35.tar.gz 安装12345# 解压到/opt/tomcat目录下tar -zvxf apache-tomcat-8.5.35.tar.gz -C /opt/tomcat# 启动tomcat,运行startup脚本/opt/tomcat/apache-tomcat-8.5.35/bin/startup.sh 查看/logs目录下的catalina.{yyyy-mm-dd}.log日志文件，出现如下信息启动成功： 配置启动脚本修改catalina.sh脚本1vim /opt/tomcat/apache-tomcat-8.5.35/bin/catalina.sh 在文件头部添加如下内容：123456# Tomcat service#chkconfig:2345 10 90#description:Tomcat serviceexport CATALINA_HOME=/opt/tomcat/apache-tomcat-8.5.35export JAVA_HOME=/opt/java/jdk1.8.0_191 chkconfig 2345 10 90：分别定义了tomcat的启动级别、关闭和启动优先级。CATALINA_HOME：tomcat目录JAVA_HOME：jdk目录 添加系统服务12345678# 添加启动脚本到服务脚本文件夹ln -s /opt/tomcat/apache-tomcat-8.5.35/bin/catalina.sh /etc/init.d/tomcat# 添加到系统服务chkconfig --add tomcat# 设置开机启动chkconfig tomcat on 服务命令12345# 启动服务service tomcat start# 停止服务service tomcat stop 控制台输出的信息无法确定tomcat是否成功启动/停止，请查看日志文件 配置防火墙端口tomcat默认端口是8080，配置防火墙打开对应端口。12345vim /etc/sysconfig/iptables-A INPUT -m state --state NEW -m tcp -p tcp --dport 8080 -j ACCEPT# 重启防火墙service iptables restart 如果是阿里云服务器，还需要在安全组规则中开启8080端口。 访问tomcat服务器tomcat默认网页目录是../apache-tomcat-8.5.35/webapp。在浏览器中输入ip:8080，出现如下页面，则tomcat访问成功。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>java</tag>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux安装jdk]]></title>
    <url>%2F2018%2F12%2F16%2Finstall-jdk-on-centos%2F</url>
    <content type="text"><![CDATA[本文环境 Centos6.8 64位，安装版本 jdk1.8.0_191 下载jdk官网下载下载地址：https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html选择jdk-8u191-linux-x64.tar.gz下载。 wget命令下载1wget https://download.oracle.com/otn-pub/java/jdk/8u191-b12/2787e4a523244c269598db4e85c51e0c/jdk-8u191-linux-x64.tar.gz 安装12# 解压到/opt/java/jdk1.8.0_191目录下tar -zvxf jdk-8u191-linux-x64.tar.gz -C /opt/java/ 配置jdk环境变量123456789101112# 编辑全局变量文件vim /etc/profile# 在文件末尾添加如下内容：# JAVA_HOMEexport JAVA_HOME=/opt/java/jdk1.8.0_191export JRE_HOME=$JAVA_HOME/jreexport CLASSPATH=.:$JAVA_HOME/lib/export PATH=$PATH:$JAVA_HOME/bin# 使全局变量文件生效source /etc/profile 检查安装成功12# 查看jdk版本java -version]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux二进制文件安装mysql]]></title>
    <url>%2F2018%2F12%2F12%2Finstall-mysql-binary-on-centos%2F</url>
    <content type="text"><![CDATA[本文环境Centos6.8 64位，安装版本Mysql5.7.24 下载软件官网下载官网下载地址：https://dev.mysql.com/downloads/mysql/选择如下文件下载： wget下载：123# root用户执行cd ~wget https://cdn.mysql.com//Downloads/MySQL-5.7/mysql-5.7.24-linux-glibc2.12-x86_64.tar.gz 创建mysql用户12groupadd mysqluseradd -r -g mysql mysql 安装解压缩123# 解压到/opt目录下，重命名文件夹tar -zvxf mysql-5.7.24-linux-glibc2.12-x86_64.tar.gz -C /optmv /opt/mysql-5.7.24-linux-glibc2.12-x86_64 /opt/mysql-5.7.24 查看系统是否已安装mysql1rpm -qa | grep -i mysql 如图本系统并未安装mysql 配置数据库目录12345mkdir -p /opt/mysql-5.7.24/&#123;data,log,etc,run,tmp&#125;touch /opt/mysql-5.7.24/etc/my.cnftouch /opt/mysql-5.7.24/log/&#123;mysql_error.log,mysql_bin.log,mysql_slow_query.log&#125;touch /opt/mysql-5.7.24/run/mysql.socktouch /opt/mysql-5.7.24/run/mysql.pid 目录说明： 数据目录 /opt/mysql-5.7.24/data 配置文件 /opt/mysql-5.7.24/etc/my.cnf 错误日志 /opt/mysql-5.7.24/log/mysql_error.log 二进制日志 /opt/mysql-5.7.24/log/mysql_bin.log 慢查询日志 /opt/mysql-5.7.24/log/mysql_slow_query.log 套接字socket文件 /opt/mysql-5.7.24/run/mysql.sock pid文件 /opt/mysql-5.7.24/run/mysql.sock 修改文件夹拥有者为mysql1chown -R mysql:mysql /opt/mysql-5.7.24 设置环境变量12345678vim /etc/profile# 在文件末尾追加如下内容# MYSQL_HOMEexport MYSQL_HOME=/opt/mysql-5.7.24export PATH=$PATH:$MYSQL_HOME/binsource /etc/profile 编辑my.cnf配置文件部分参数填写的路径要与前面设置的mysql路径一致，配置文件如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697# vim /opt/mysql-5.7.24/etc/my/cnf# 内容同步至/etc/my.cnf[client]port = 3306socket = /opt/mysql-5.7.24/run/mysql.sockdefault-character-set = utf8mb4[mysqld_safe]socket = /opt/mysql-5.7.24/run/mysql.socknice = 0[mysqld]## * Base Setting#pid_file = /opt/mysql-5.7.24/run/mysql.pidsocket = /opt/mysql-5.7.24/run/mysql.sockport = 3306user = mysqlbasedir = /opt/mysql-5.7.24datadir = /opt/mysql-5.7.24/datatmpdir = /opt/mysql-5.7.24/tmplc-messages-dir = /usr/share/mysqlskip-external-locking## Instead of skip-networking the default is now to listen only on# localhost which is more compatible and is not less secure.# bind-address = 127.0.0.1## * Fine Tuning#key_buffer_size = 16Mmax_allowed_packet = 16Mthread_stack = 192Kthread_cache_size = 8# This replaces the startup script and checks MyISAM tables if needed# the first time they are touchedmyisam-recover-options = BACKUP#max_connections = 100#table_cache = 64#thread_concurrency = 10## * Query Cache Configuration#query_cache_limit = 1Mquery_cache_size = 16M## * Logging and Replication## Both location gets rotated by the cronjob.# Be aware that this log type is a performance killer.# As of 5.1 you can enable the log at runtime!#general_log_file = /var/log/mysql/mysql.log#general_log = 1## Error log - should be very few entries.#log_error = /opt/mysql-5.7.24/log/mysql_error.log## Here you can see queries with especially long durationslow_query_log = onslow-query-log-file = /opt/mysql-5.7.24/mysql_slow_query.log#long_query_time = 2#log-queries-not-using-indexes## The following can be used as easy to replay backup logs or for replication.# note: if you are setting up a replication slave, see README.Debian about# other settings you may need to change.#server-id = 1#log_bin = /opt/mysql-5.7.24/log/mysql_bin.logexpire_logs_days = 10max_binlog_size = 100M#binlog_do_db = include_database_name#binlog_ignore_db = include_database_name## * InnoDB## InnoDB is enabled by default with a 10MB datafile in /var/lib/mysql/.# Read the manual for more InnoDB related options. There are many!## * Security Features## Read the manual, too, if you want chroot!# chroot = /var/lib/mysql/## For generating SSL certificates I recommend the OpenSSL GUI "tinyca".## ssl-ca=/etc/mysql/cacert.pem# ssl-cert=/etc/mysql/server-cert.pem# ssl-key=/etc/mysql/server-key.pemsymbolic-links=0 初始化1mysqld --initialize --user=mysql --basedir=/opt/mysql-5.7.24 --datadir=/opt/mysql-5.7.24/data 系统会生成一个临时密码记得保存； 如果出现错误，查看/opt/mysql-5.7.24/log/mysql_error.log日志。 安装结果如图： mysql配置系统服务修改mysqld文件123456789# 拷贝mysql.server到/etc/init.d/mysqld文件cp /opt/mysql-5.7.24/support-files/mysql.server /etc/init.d/mysqld#设置mysqld文件中的路径vim /etc/init.d/mysqld# 设置basedir和datadirbasedir=/opt/mysql-5.7.24datadir=/opt/mysql-5.7.24/data 加入服务1chkconfig --add mysqld 设置开机启动和查看设置状态12chkconfig mysqld onchkconfig mysqld --list 启动mysql服务12# 可选参数 start|stop|restartservice mysqld start 我在这里遇到了错误 Starting MySQL…The server quit without updating PID file [FAILED]sql-5.7.24/data/iZuf65pgqo8iyipci611e6Z.pid). 原因是/opt/mysql-5.7.24/run/文件夹下的mysql.pid和mysql.sock没有执行权限1chmod -R 755 /opt/mysql-5.7.24/run/ 查看mysql服务状态1service mysqld status 登录mysql，修改root密码123456789mysql -u root -pEnter password: [输入临时密码]mysql&gt; ALTER USER 'root'@'localhost' IDENTIFIED BY '新密码';mysql&gt; flush privileges;mysql&gt; exit;# 重新登录mysql -u root -pEnter password: [新密码] End]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git自动部署hexo博客到服务器]]></title>
    <url>%2F2018%2F12%2F09%2Fdeploy-hexo2server-by-git%2F</url>
    <content type="text"><![CDATA[环境搭建 本地(Windows) node.js hexo 远程服务器(Linux) git nginx 相关文章： Linux安装git Linux安装nginx git设置git命令添加软连接如果git没有安装在/usr/bin/git，需要为/git/bin目录下的命令添加软连接。否则，同步时会出现git-receive-pack:command not found错误。 12345678# 我的git安装在了/opt目录下ln -s /opt/git/bin/git-upload-pack /usr/bin/git-upload-packln -s /opt/git/bin/git-upload-archive /usr/bin/git-upload-archiveln -s /opt/git/bin/git-shell /usr/bin/git-shellln -s /opt/git/bin/git-receive-pack /usr/bin/git-receive-packln -s /opt/git/bin/gitk /usr/bin/gitkln -s /opt/git/bin/git-cvsserver /usr/bin/git-cvsserverln -s /opt/git/bin/git /usr/bin/git 初始化git仓库12345678910# 切换到git 用户su git# 创建仓库cd /home/gitmkdir hexo.git#初始化仓库cd hexo.gitgit init --bare 配置SSH将本地的公钥复制到/home/git/.ssh/authorized_keys文件中。 测试SSH登录1ssh -i [公钥路径] -p [端口号] git@服务器ip 创建SSH config文件如果服务器修改了SSH默认端口，可以在本地的.ssh目录下创建config文件，方便hexo deploy时访问指定端口。配置文件内容如下：12345Host 服务器ipHostName 服务器ipUser gitPort SSH端口号IdentityFile ~/.ssh/git_rsa 配置git Hooks创建post-receive文件12cd /home/git/hexo.git/hooksvim post-receive 编辑文件内容12345678#!/bin/bashGIT_REPO=/home/git/hexo.gitTMP_GIT_CLONE=/tmp/hexoPUBLIC_WWW=/var/www/htmlrm -rf $&#123;TMP_GIT_CLONE&#125;git clone $GIT_REPO $TMP_GIT_CLONErm -rf $&#123;PUBLIC_WWW&#125;/*cp -rf $&#123;TMP_GIT_CLONE&#125;/* $&#123;PUBLIC_WWW&#125; 确认文件权限post-receive文件中提到了三个目录： /home/git/hexo.git /tmp/hexo /var/www/html 需确保以上三个目录和目录中所有的文件拥有者为git。可以通过chown命令修改拥有者。12sudo chown git:git -R /var/wwwsudo chown git:git -R /home/git/hexo.git 配置本地hexo修改本地hexo目录下的_config.ym，修改deploy配置：12345678910# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: - type: git repo: git@github.com:&lt;username&gt;/&lt;username&gt;.github.io.git branch: master - type: git repo: &lt;username&gt;@服务器ip:hexo.git branch: master 同步本地执行hexo d命令，博客成功同步到服务器的/var/www/html中，则搭建成功。]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>git</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux源代码安装nodejs]]></title>
    <url>%2F2018%2F12%2F09%2Finstall-nodejs-on-centos%2F</url>
    <content type="text"><![CDATA[下载官网：http://nodejs.cn/download/1wget http://cdn.npm.taobao.org/dist/node/v10.14.1/node-v10.14.1.tar.gz 安装依赖工具1yum install python gcc make g++ wget 解压编译安装12345678#解压tar -zvxf node-v10.14.1.tar.gz# 编译&amp;安装cd node-v10.14.1/./configure --prefix=/opt/nodejsmake prefix=/opt/nodejsmake prefix=/opt/nodejs install 编译报错1234which: no python2.7 in (/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/opt/git/bin:/root/bin)ERROR: Did not find a new enough assembler, install one or build with --openssl-no-asm. Please refer to BUILDING.md 安装python2.7123456789101112131415#下载cd /usr/local/srccurl https://www.python.org/ftp/python/2.7.14/Python-2.7.14.tgz -o python-2.7.14.tgz# 解压tar -zxvf Python-2.7.14.tgzcd Python-2.7.14./configure# 编译&amp;安装makemake install#查看版本python --version 查看版本12node -vnpm -v]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux源代码安装nginx]]></title>
    <url>%2F2018%2F12%2F09%2Finstall-nginx-on-centos%2F</url>
    <content type="text"><![CDATA[本文安装环境 Centos6.8 64位，安装版本 nginx 1.14.2 一、下载源代码官网：http://nginx.org/en/download.html 1wget http://nginx.org/download/nginx-1.14.2.tar.gz 二、安装依赖工具yum安装1yum -y install gcc gcc-c++ autoconf automake zlib zlib-devel openssl openssl-devel pcre 手动安装依赖，举例pcre库1234567cd /usr/local/srcwget https://ftp.pcre.org/pub/pcre/pcre-8.36.tar.gztar -zxvf pcre-8.36.tar.gzcd pcre-8.36./configuremakemake install 三、编译和安装12345678# 解压tar -zvxf nginx-1.14.2.tar.gz# 编译和安装cd nginx-1.14.2./configure --prefix=/opt/nginx make prefix=/opt/nginxmake prefix=/opt/nginx install 四、启动nginx1/opt/nginx/sbin/nginx 访问浏览器，输入IP，显示“Welcome to nginx!”。 五、添加nginx到系统服务1、编写nginx文件在/etc/init.d目录下编写nginx文件1vim /etc/init.d/nginx nginx文件内容如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101#!/bin/bash# nginx Startup script for the Nginx HTTP Server# this script create it by caffreyxin at 2007.10.15.# it is v.0.0.1 version.# if you find any errors on this scripts, please contact caffreyxin.# and send mail to xinyflove at sina dot com.## chkconfig: - 85 15# description: Nginx is a high-performance web and proxy server.# It has a lot of features, but it's not for everyone.# processname: nginx# pidfile: /var/run/nginx.pid# config: /usr/local/nginx/conf/nginx.conf# nginx directorynginxd=/opt/nginx/sbin/nginxnginx_config=/opt/nginx/conf/nginx.confnginx_pid=/var/run/nginx.pidRETVAL=0prog="nginx"# Source function library.. /etc/rc.d/init.d/functions# Source networking configuration.. /etc/sysconfig/network# Check that networking is up.[ $&#123;NETWORKING&#125; = "no" ] &amp;&amp; exit 0[ -x $nginxd ] || exit 0# Start nginx daemons functions.start() &#123; if [ -e $nginx_pid ];then echo "nginx already running...." exit 1 fi echo -n $"Starting $prog: " daemon $nginxd -c $&#123;nginx_config&#125; RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; touch /var/lock/subsys/nginx return $RETVAL&#125;# Stop nginx daemons functions.stop() &#123; echo -n $"Stopping $prog: " killproc $nginxd RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; rm -f /var/lock/subsys/nginx /var/run/nginx.pid&#125;# reload nginx service functions.reload() &#123; echo -n $"Reloading $prog: " #kill -HUP `cat $&#123;nginx_pid&#125;` killproc $nginxd -HUP RETVAL=$? echo&#125;# See how we were called.case "$1" instart) start ;;stop) stop ;;reload) reload ;;restart) stop start ;;status) status $prog RETVAL=$? ;;*) echo $"Usage: $prog &#123;start|stop|restart|reload|status|help&#125;" exit 1esacexit $RETVAL 2、添加到系统服务1234567# 添加到系统服务chkconfig --add /etc/init.d/nginxchmod 755 /etc/init.d/nginxchkconfig --add nginx# 设置开机自启动/sbin/chkconfig --level 345 nginx on 3、启动、停止、无间断重启1234# 可选 start | stop | restart | reload | status | helpservice nginx startservice nginx stopservice nginx reload]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux源代码安装git]]></title>
    <url>%2F2018%2F12%2F09%2Finstall-git-on-centos%2F</url>
    <content type="text"><![CDATA[本文安装环境 Centos6.8 64位，安装版本 git-2.19.2 一、下载git源代码github：https://github.com/git/git/releases官网：http://git-scm.com/download 二、安装依赖工具git的工作需要调用 curl，zlib，openssl，expat，libiconv 等库的代码，所以需要先安装这些依赖工具。Centos安装有yum，可以使用以下命令12yum install curl-devel expat-devel gettext-devel \ openssl-devel zlib-devel 三、创建git用户添加root权限12345678910111213# 新建用户useradd git# sudoers文件添加写入、执行权限chmod 740 /etc/sudoers# 修改sudoers文件vim /etc/sudoers# 在/etc/sudoers找到root ALL=(ALL) ALL，# 在下面添加一行：git ALL=(ALL) ALL# sudoers文件恢复只读权限chmod 440 /etc/sudoers 四、编译安装安装包上传到/opt目录，然后解压安装。 1234567# 解压tar -zvxf git-2.19.2.tar.gz# 编译安装cd git-2.19.2make prefix=/opt/git allsudo make prefix=/opt/git install 安装成功后会在/opt目录下出现/git文件夹。 五、git配置环境变量为了便于使用git命令，还需要将git添加到环境变量中。12345678910111213# 修改环境变量配置文件vim /etc/profile# 在文件末尾添加# GIT_HOMEexport GIT_HOME=/opt/git/binexport PATH=$PATH:$GIT_HOME# 输出环境变量export $PATH# 使配置文件修改生效source /etc/profile 六、git命令1、查看git版本，确认安装和环境变量配置成功。1git --version 2、初始化仓库1234567# 在/home/git下新建文件夹cd /home/gitmkdir Hellogitcd Hellogit/# 初始化仓库git init]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>git</tag>
      </tags>
  </entry>
</search>
